{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hello\\AppData\\Local\\Temp\\ipykernel_14280\\3232262050.py:2: DtypeWarning: Columns (32,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/dataset.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('../data/dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handling Missing Data:**\n",
    " Impute or remove missing values based on their nature and the quantity missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Missing Data (Drop rows with missing values or apply imputation as needed)\n",
    "df = df.dropna() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Engineering:**\n",
    " Create new features that might be relevant to TotalPremium and TotalClaims.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering: Create new features based on domain knowledge (e.g., 'Claim Ratio')\n",
    "df['ClaimRatio'] = df['TotalClaims'] / (df['TotalPremium'] + 1)  # Add 1 to avoid division by zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding Categorical Data:**\n",
    " Convert categorical data into a numeric format using one-hot encoding or label encoding to make it suitable for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Categorical Data\n",
    "# Using Label Encoding for binary categorical columns (Gender, LegalType)\n",
    "le = LabelEncoder()\n",
    "df['Gender'] = le.fit_transform(df['Gender'])\n",
    "df['LegalType'] = le.fit_transform(df['LegalType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using One-Hot Encoding for multi-class categorical columns (Province, PostalCode, etc.)\n",
    "df = pd.get_dummies(df, columns=['Province', 'PostalCode', 'VehicleType'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target variable (e.g., predicting TotalPremium or TotalClaims)\n",
    "X = df.drop(columns=['TotalPremium', 'TotalClaims'])  # Features\n",
    "y = df['TotalPremium']  # Target variable (or 'TotalClaims')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (0, 48)\n",
      "Shape of y: (0,)\n",
      "X or y is empty. Please check your data preparation.\n"
     ]
    }
   ],
   "source": [
    "# Check shapes again\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "\n",
    "# Train-Test Split (80:20 ratio)\n",
    "if not X.empty and not y.empty:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "else:\n",
    "    print(\"X or y is empty. Please check your data preparation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train-Test Split:**\n",
    " Divide the data into a training set (for building the model) and a test set (for validating the model), typically using a 70:30 or 80:20 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X or y is empty after handling missing values. Please check your data preparation.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define your features and target variable\n",
    "X = df.drop(columns=['TotalPremium', 'TotalClaims'], errors='ignore')  # Features\n",
    "y = df['TotalPremium']  # Target variable\n",
    "\n",
    "# Check for missing values in X and y\n",
    "if X.isnull().values.any():\n",
    "    print(\"Missing values found in features. Handling them...\")\n",
    "    # Option 1: Fill missing values with the mean (for numerical features)\n",
    "    X = X.fillna(X.mean())\n",
    "    # Option 2: Drop rows with missing values (if appropriate)\n",
    "    # X = X.dropna()\n",
    "\n",
    "if y.isnull().any():\n",
    "    print(\"Missing values found in target variable. Handling them...\")\n",
    "    # Fill missing values in the target variable\n",
    "    y = y.fillna(y.mean())  # Or you can choose to drop rows where y is NaN\n",
    "    # y = y.dropna()\n",
    "\n",
    "# Check if the data is empty after handling missing values\n",
    "if X.empty or y.empty:\n",
    "    print(\"X or y is empty after handling missing values. Please check your data preparation.\")\n",
    "else:\n",
    "    # Train-Test Split (80:20 ratio)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(\"Train-Test split successful.\")\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_test shape:\", X_test.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Building and Evaluation\n",
    "\n",
    "2.1 Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X or y is empty after handling missing values. Please check your data preparation.\n"
     ]
    }
   ],
   "source": [
    "# Define your features and target variable\n",
    "X = df.drop(columns=['TotalPremium', 'TotalClaims'], errors='ignore')  # Features\n",
    "y = df['TotalPremium']  # Target variable\n",
    "\n",
    "# Check for missing values in X and y\n",
    "if X.isnull().values.any():\n",
    "    print(\"Missing values found in features. Handling them...\")\n",
    "    # Fill missing values with the mean for numerical features\n",
    "    X = X.fillna(X.mean())\n",
    "\n",
    "if y.isnull().any():\n",
    "    print(\"Missing values found in target variable. Handling them...\")\n",
    "    # Fill missing values in the target variable\n",
    "    y = y.fillna(y.mean()) \n",
    "\n",
    "# Check if the data is empty after handling missing values\n",
    "if X.empty or y.empty:\n",
    "    print(\"X or y is empty after handling missing values. Please check your data preparation.\")\n",
    "else:\n",
    "    # Train-Test Split (80:20 ratio)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Linear Regression Model\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    lr_predictions = lr_model.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    mse = mean_squared_error(y_test, lr_predictions)\n",
    "    r2 = r2_score(y_test, lr_predictions)\n",
    "    print(\"Linear Regression MSE:\", mse)\n",
    "    print(\"Linear Regression R²:\", r2)\n",
    "\n",
    "    # Random Forest Model\n",
    "    rf_model = RandomForestRegressor()\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    rf_mse = mean_squared_error(y_test, rf_predictions)\n",
    "    rf_r2 = r2_score(y_test, rf_predictions)\n",
    "    print(\"Random Forest MSE:\", rf_mse)\n",
    "    print(\"Random Forest R²:\", rf_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Model Building\n",
    "Implement Linear Regression, Random Forests, and XGBoost models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 XGBoost\n",
    "xgb_model = XGBRegressor(random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_predictions = xgb_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Model Evaluation\n",
    "def evaluate_model(true, pred, model_name):\n",
    "    mse = mean_squared_error(true, pred)\n",
    "    r2 = r2_score(true, pred)\n",
    "    print(f'{model_name} - Mean Squared Error: {mse:.2f}, R2 Score: {r2:.2f}')\n",
    "\n",
    "evaluate_model(y_test, lr_predictions, \"Linear Regression\")\n",
    "evaluate_model(y_test, rf_predictions, \"Random Forest\")\n",
    "evaluate_model(y_test, xgb_predictions, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m lr_model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m----> 2\u001b[0m lr_model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[0;32m      3\u001b[0m lr_predictions \u001b[38;5;241m=\u001b[39m lr_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
